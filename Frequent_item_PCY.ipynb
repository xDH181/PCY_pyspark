{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finding frequent items\n"
      ],
      "metadata": {
        "id": "gyf22UZqbwdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init step"
      ],
      "metadata": {
        "id": "JW_DCq8y3N2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "g9eWGrpzGk_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1260b417-c22c-45d7-9022-ad411016cd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, split, collect_set\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "from pyspark.sql import Row\n",
        "from pyspark.rdd import RDD"
      ],
      "metadata": {
        "id": "t49Y4tgSfqes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PCY Algorithm\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "uN9KIK-53I6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## read input file"
      ],
      "metadata": {
        "id": "8IlFDVfh3Xs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/Big-Midterm/baskets.csv\"\n",
        "\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJh99-9A3Ti0",
        "outputId": "48c00d1c-a691-4bf1-da4e-d99aa6cfc3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+----------------+----+-----+---+-----------+\n",
            "|Member_number|      Date| itemDescription|year|month|day|day_of_week|\n",
            "+-------------+----------+----------------+----+-----+---+-----------+\n",
            "|         1249|01/01/2014|    citrus fruit|2014|    1|  1|          2|\n",
            "|         1249|01/01/2014|          coffee|2014|    1|  1|          2|\n",
            "|         1381|01/01/2014|            curd|2014|    1|  1|          2|\n",
            "|         1381|01/01/2014|            soda|2014|    1|  1|          2|\n",
            "|         1440|01/01/2014|other vegetables|2014|    1|  1|          2|\n",
            "+-------------+----------+----------------+----+-----+---+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "wkbFFAb2f_JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### group by member & date"
      ],
      "metadata": {
        "id": "yJEg28lj4C6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_basket = df.groupBy(\"Member_number\", \"Date\") \\\n",
        "    .agg(collect_set(\"itemDescription\").alias(\"basket\"))\n",
        "\n",
        "df_basket.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZm8vkM0gEvo",
        "outputId": "c51ec43b-1a77-4408-eb67-c66ea7aa6444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+--------------------------------------------------+\n",
            "|Member_number|Date      |basket                                            |\n",
            "+-------------+----------+--------------------------------------------------+\n",
            "|1000         |15/03/2015|[whole milk, sausage, yogurt, semi-finished bread]|\n",
            "|1000         |24/06/2014|[pastry, whole milk, salty snack]                 |\n",
            "|1000         |24/07/2015|[misc. beverages, canned beer]                    |\n",
            "|1000         |25/11/2015|[sausage, hygiene articles]                       |\n",
            "|1000         |27/05/2015|[pickled vegetables, soda]                        |\n",
            "+-------------+----------+--------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCY"
      ],
      "metadata": {
        "id": "4PvaebYzn8go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### init PCY"
      ],
      "metadata": {
        "id": "qvftRu748Heh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HashBucket:\n",
        "    \"\"\"\n",
        "    Implements a hash table for the PCY algorithm to store and count hashed pairs.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_buckets):\n",
        "        self.num_buckets = num_buckets\n",
        "        self.buckets = [0] * num_buckets  # Initialize bucket counts\n",
        "\n",
        "    def hash_function(self, item1, item2):\n",
        "        \"\"\"\n",
        "        Hash function for hashing item pairs into buckets.\n",
        "        \"\"\"\n",
        "        return (hash(item1) ^ hash(item2)) % self.num_buckets\n",
        "\n",
        "    def increment_bucket(self, item1, item2):\n",
        "        \"\"\"\n",
        "        Increments the count of a bucket corresponding to a given pair.\n",
        "        \"\"\"\n",
        "        index = self.hash_function(item1, item2)\n",
        "        self.buckets[index] += 1\n",
        "\n",
        "    def is_frequent(self, item1, item2, threshold):\n",
        "        \"\"\"\n",
        "        Checks if a hashed pair meets the frequency threshold.\n",
        "        \"\"\"\n",
        "        index = self.hash_function(item1, item2)\n",
        "        return self.buckets[index] >= threshold"
      ],
      "metadata": {
        "id": "vFqPk1F8oMj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PCY:\n",
        "    \"\"\"\n",
        "    Implementation of the PCY (Park-Chen-Yu) algorithm for frequent itemset mining.\n",
        "    \"\"\"\n",
        "    def __init__(self, min_support, num_buckets, min_confidence, spark):\n",
        "        \"\"\"\n",
        "        Initializes the PCY algorithm with minimum support, hash bucket count, and confidence threshold.\n",
        "        \"\"\"\n",
        "        self.min_support = min_support\n",
        "        self.min_confidence = min_confidence\n",
        "        self.num_buckets = num_buckets\n",
        "        self.hash_table = HashBucket(num_buckets)  # Create a hash bucket instance\n",
        "        self.spark = spark  # Store Spark session for DataFrame operations\n",
        "\n",
        "    def first_pass(self, baskets):\n",
        "        \"\"\"\n",
        "        First pass of PCY: Counts item frequencies and hashes pairs into buckets.\n",
        "        \"\"\"\n",
        "        if isinstance(baskets, RDD):  # If input is an RDD\n",
        "            item_counts = baskets.flatMap(lambda basket: [(item, 1) for item in basket]) \\\n",
        "                                .reduceByKey(lambda a, b: a + b)\n",
        "            frequent_items = item_counts.filter(lambda x: x[1] >= self.min_support).collectAsMap()\n",
        "        else:\n",
        "            item_counts = defaultdict(int)\n",
        "            for basket in baskets:\n",
        "                for item in basket:\n",
        "                    item_counts[item] += 1  # Count item occurrences\n",
        "                for item1, item2 in combinations(basket, 2):\n",
        "                    self.hash_table.increment_bucket(item1, item2)  # Hash item pairs\n",
        "            frequent_items = {item: count for item, count in item_counts.items() if count >= self.min_support}\n",
        "\n",
        "        self.frequent_items = frequent_items\n",
        "        return frequent_items\n",
        "\n",
        "    def second_pass(self, baskets):\n",
        "        \"\"\"\n",
        "        Second pass of PCY: Identifies frequent item pairs.\n",
        "        \"\"\"\n",
        "        if isinstance(baskets, RDD):\n",
        "            pair_counts = baskets.flatMap(lambda basket: [(pair, 1) for pair in combinations(basket, 2)\n",
        "                                                           if self.hash_table.is_frequent(pair[0], pair[1], self.min_support)\n",
        "                                                           and pair[0] in self.frequent_items and pair[1] in self.frequent_items]) \\\n",
        "                                .reduceByKey(lambda a, b: a + b)\n",
        "            frequent_pairs = pair_counts.filter(lambda x: x[1] >= self.min_support).collectAsMap()\n",
        "        else:\n",
        "            pair_counts = defaultdict(int)\n",
        "            for basket in baskets:\n",
        "                for item1, item2 in combinations(basket, 2):\n",
        "                    if self.hash_table.is_frequent(item1, item2, self.min_support):\n",
        "                        if item1 in self.frequent_items and item2 in self.frequent_items:\n",
        "                            pair_counts[(item1, item2)] += 1  # Count frequent pairs\n",
        "            frequent_pairs = {pair: count for pair, count in pair_counts.items() if count >= self.min_support}\n",
        "\n",
        "        self.frequent_pairs = frequent_pairs\n",
        "        return frequent_pairs\n",
        "\n",
        "    def generate_association_rules(self, baskets):\n",
        "        \"\"\"\n",
        "        Generates association rules from frequent item pairs.\n",
        "        \"\"\"\n",
        "        if isinstance(baskets, RDD):\n",
        "            item_counts = baskets.flatMap(lambda basket: [(item, 1) for item in basket]) \\\n",
        "                                 .reduceByKey(lambda a, b: a + b) \\\n",
        "                                 .collectAsMap()\n",
        "        else:\n",
        "            item_counts = defaultdict(int)\n",
        "            for basket in baskets:\n",
        "                for item in basket:\n",
        "                    item_counts[item] += 1  # Count individual items\n",
        "\n",
        "        rules = []\n",
        "        for (A, B), support_AB in self.frequent_pairs.items():\n",
        "            confidence_AB = support_AB / item_counts[A]\n",
        "            confidence_BA = support_AB / item_counts[B]\n",
        "            if confidence_AB >= self.min_confidence:\n",
        "                rules.append(Row(antecedent=A, consequent=B, confidence=confidence_AB))\n",
        "            if confidence_BA >= self.min_confidence:\n",
        "                rules.append(Row(antecedent=B, consequent=A, confidence=confidence_BA))\n",
        "\n",
        "        return self.spark.createDataFrame(rules)  # Convert to DataFrame\n",
        "\n",
        "    def debug_first_pass(self, baskets):\n",
        "        \"\"\"\n",
        "        Debug method: Runs the first pass and prints key results.\n",
        "        \"\"\"\n",
        "        print(\"[DEBUG] Starting first pass...\")\n",
        "        frequent_items = self.first_pass(baskets)\n",
        "        print(f\"===============================\\nTotal frequent items: {len(frequent_items)}\")\n",
        "        return self.spark.createDataFrame([Row(item=item, count=count) for item, count in frequent_items.items()])\n",
        "\n",
        "    def debug_second_pass(self, baskets):\n",
        "        \"\"\"\n",
        "        Debug method: Runs the second pass and prints key results.\n",
        "        \"\"\"\n",
        "        print(\"[DEBUG] Starting second pass...\")\n",
        "        frequent_pairs = self.second_pass(baskets)\n",
        "        print(f\"===============================\\nTotal frequent pairs: {len(frequent_pairs)}\")\n",
        "        return self.spark.createDataFrame([Row(item1=p[0], item2=p[1], count=count) for p, count in frequent_pairs.items()])\n",
        "\n",
        "    def debug_generate_association_rules(self, baskets):\n",
        "        \"\"\"\n",
        "        Debug method: Generates association rules and prints key results.\n",
        "        \"\"\"\n",
        "        print(\"[DEBUG] Generating association rules...\")\n",
        "        rules_df = self.generate_association_rules(baskets)\n",
        "        print(f\"===============================\\nTotal rules: {rules_df.count()}\")\n",
        "        return rules_df\n",
        "\n",
        "    def run(self, baskets):\n",
        "        \"\"\"\n",
        "        Runs the entire PCY algorithm: first pass, second pass, and rule generation.\n",
        "        \"\"\"\n",
        "        self.first_pass(baskets)\n",
        "        self.second_pass(baskets)\n",
        "        return self.generate_association_rules(baskets)\n"
      ],
      "metadata": {
        "id": "vzf_q1D17_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debug"
      ],
      "metadata": {
        "id": "MFDItjJBLVyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baskets = df_basket.select(\"basket\").rdd.flatMap(lambda x: x).collect()"
      ],
      "metadata": {
        "id": "DC6C24U08ZUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcy = PCY(min_support=20, num_buckets=500, min_confidence=0.1,spark = spark)\n",
        "\n",
        "print(\"=== First Pass ===\")\n",
        "df_frequent_items = pcy.debug_first_pass(baskets)\n",
        "df_frequent_items.show()\n",
        "\n",
        "print(\"=== Second Pass ===\")\n",
        "df_frequent_pairs = pcy.debug_second_pass(baskets)\n",
        "df_frequent_pairs.show()\n",
        "\n",
        "print(\"=== Association Rules ===\")\n",
        "df_rules = pcy.debug_generate_association_rules(baskets)\n",
        "df_rules.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtWLjuiOec8b",
        "outputId": "edd06b8f-15c1-4425-db2c-9b4dc314e73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== First Pass ===\n",
            "[DEBUG] Starting first pass...\n",
            "===============================\n",
            "Total frequent items: 141\n",
            "+-------------------+-----+\n",
            "|               item|count|\n",
            "+-------------------+-----+\n",
            "|         whole milk| 2363|\n",
            "|            sausage|  903|\n",
            "|             yogurt| 1285|\n",
            "|semi-finished bread|  142|\n",
            "|             pastry|  774|\n",
            "|        salty snack|  281|\n",
            "|    misc. beverages|  236|\n",
            "|        canned beer|  702|\n",
            "|   hygiene articles|  205|\n",
            "| pickled vegetables|  134|\n",
            "|               soda| 1453|\n",
            "|         rolls/buns| 1646|\n",
            "|        frankfurter|  565|\n",
            "|               curd|  504|\n",
            "|               beef|  508|\n",
            "|        white bread|  359|\n",
            "| whipped/sour cream|  654|\n",
            "|  frozen vegetables|  419|\n",
            "|   other vegetables| 1827|\n",
            "|             butter|  527|\n",
            "+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "=== Second Pass ===\n",
            "[DEBUG] Starting second pass...\n",
            "===============================\n",
            "Total frequent pairs: 407\n",
            "+-----------------+-------------------+-----+\n",
            "|            item1|              item2|count|\n",
            "+-----------------+-------------------+-----+\n",
            "|       whole milk|            sausage|  134|\n",
            "|       whole milk|             yogurt|  167|\n",
            "|       whole milk|semi-finished bread|   25|\n",
            "|          sausage|             yogurt|   86|\n",
            "|           pastry|         whole milk|   97|\n",
            "|       whole milk|        salty snack|   29|\n",
            "|       whole milk|         rolls/buns|  209|\n",
            "|          sausage|         rolls/buns|   80|\n",
            "|      frankfurter|               curd|   20|\n",
            "|       whole milk|               soda|  174|\n",
            "|      frankfurter|               soda|   46|\n",
            "|      frankfurter| whipped/sour cream|   22|\n",
            "|             soda| whipped/sour cream|   51|\n",
            "|frozen vegetables|   other vegetables|   47|\n",
            "|       whole milk|             butter|   70|\n",
            "|       whole milk|          pip fruit|   99|\n",
            "|       whole milk|     tropical fruit|  123|\n",
            "|        pip fruit|     tropical fruit|   31|\n",
            "|   red/blush wine|         rolls/buns|   20|\n",
            "|       rolls/buns|          chocolate|   42|\n",
            "+-----------------+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "=== Association Rules ===\n",
            "[DEBUG] Generating association rules...\n",
            "===============================\n",
            "Total rules: 93\n",
            "+-------------------+----------------+-------------------+\n",
            "|         antecedent|      consequent|         confidence|\n",
            "+-------------------+----------------+-------------------+\n",
            "|            sausage|      whole milk|0.14839424141749724|\n",
            "|             yogurt|      whole milk|0.12996108949416343|\n",
            "|semi-finished bread|      whole milk|  0.176056338028169|\n",
            "|             pastry|      whole milk|0.12532299741602068|\n",
            "|        salty snack|      whole milk|0.10320284697508897|\n",
            "|         rolls/buns|      whole milk|0.12697448359659783|\n",
            "|               soda|      whole milk|0.11975223675154852|\n",
            "|  frozen vegetables|other vegetables|0.11217183770883055|\n",
            "|             butter|      whole milk|0.13282732447817835|\n",
            "|          pip fruit|      whole milk|0.13487738419618528|\n",
            "|     tropical fruit|      whole milk|0.12130177514792899|\n",
            "|     red/blush wine|      rolls/buns|0.12738853503184713|\n",
            "|          chocolate|      rolls/buns|0.11898016997167139|\n",
            "|      shopping bags|other vegetables|0.10393258426966293|\n",
            "|   hygiene articles|other vegetables| 0.1024390243902439|\n",
            "|          chocolate|      whole milk|0.12464589235127478|\n",
            "|    root vegetables|      whole milk|0.10854947166186359|\n",
            "|              flour|      whole milk|  0.136986301369863|\n",
            "|        frankfurter|      whole milk|0.13982300884955753|\n",
            "|            chicken|      whole milk| 0.1223021582733813|\n",
            "+-------------------+----------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}